name = WM
description = dlPFC random
experiment_number = 2  
default = true

start_neuron = 0
observation_time_ms = 200
end_time_ms = -1

# todo segments {nid@ms;},  then a specific situation can be re-tested
# output in the same format at verbosity 1  in random walk
# markov: former n-states -> new state
#
# Loop #75 State Neuron[0], Duration = 180
# Loop #76 State Neuron[3], Duration = 23
# Loop #77 State Neuron[4], Duration = 149

selection = 0;1;3;5;2;4;5;
training_loops = 20

verbosity = 2

# test trails should not alter the subjects
# experiment 1 and 2 but not 3
#update_delays = 0

# run n trails, -1 (default) = all)
#trails=2
#landmarks=(1,9);(16,10);(1,9);
#landmarks=(16,10);(1,9);
#landmarks=(1,9);(16,10);(1,9);(4,4);(10,12);(16,2);(16,10);

#initial_current = 30
#recovery_time_ms = 10
#time_grid_ms = 250
#slow_motion = 0.006
##fast_forward = 1.0
#start_time_ms = 100

# FIXME: E-Prop has to take cost discout into account
# discount costs on entering a new place or leaving the old 
discount = 1


